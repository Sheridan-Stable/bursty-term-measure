{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FUcGS9WsjDuM"
   },
   "source": [
    "# Evaluate Term Dispersion Scores on the GENIA Corpus Data and Reproduce Results Reported in the Mannuscript \n",
    "\n",
    "Authors: Samuel Sarria Hurtado, Uyen \"Rachel\" Lai, and Paul Sheridan\n",
    "\n",
    "Last update: 2025-06-03\n",
    "\n",
    "Description: Evaluate the following term dispersion scores on the Genia corpus data:\n",
    "- Inverse Document Frequency (IDF)\n",
    "- Inverse Collection Frequency (ICF)\n",
    "- Chi-square\n",
    "- Church and Gale (CG)\n",
    "- Irvine and Callison-Burch (ICB)\n",
    "- Derivation of Proportions (DoP)\n",
    "- Residual ICF (RICF)\n",
    "\n",
    "Calculate average P@k scores for each scoring function using the GENIA terms as ground truth. Also, evaluate scoring functions for their ability to filter out stopwords. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91NU-MJcn4rq"
   },
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "sys.path.append('../0-base-functions/')\n",
    "import wordstats\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from io import StringIO\n",
    "from numpy import nan\n",
    "from tqdm import tqdm\n",
    "import rbo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADCYDIp4xqU4"
   },
   "source": [
    "## Load the GENIA Corpus Data\n",
    "\n",
    "In particular, we load the\n",
    "- preprocessed GENIA corpus documents,\n",
    "- and gold standard biological terms (i.e., lexical units) and their associated semantic classes (i.e., sems)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iE_1xCV52z4V"
   },
   "outputs": [],
   "source": [
    "# Load the preprocessed GENIA corpus documents\n",
    "genia_corpus_path = '../1-preprocessing/GENIAcorpus3.02-preprocessed.json'\n",
    "\n",
    "with open(genia_corpus_path, \"r\") as j:\n",
    "  genia_corpus = json.loads(j.read())\n",
    "\n",
    "# Load gold standard terms \n",
    "genia_keywords_path = '../1-preprocessing/GENIAcorpus3.02-keywords.tsv'\n",
    "\n",
    "with open(genia_keywords_path, \"r\") as c:\n",
    "  genia_lexical_units_and_sems = pd.read_csv(c, sep='\\t')\n",
    "\n",
    "genia_lexical_units = genia_lexical_units_and_sems.lex.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPsrW3ClAKBo"
   },
   "source": [
    "## Prepare the GENIA Corpus Data for Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the corpus vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "85_RgkS4mBP3"
   },
   "outputs": [],
   "source": [
    "# Compile the GENIA corpus vocabulary\n",
    "pre_vocab = []\n",
    "for i in range(len(genia_corpus)):\n",
    "  pre_vocab.append(genia_corpus[i].split())\n",
    "\n",
    "vocab = []\n",
    "for i in range(len(pre_vocab)):\n",
    "  for j in range(len(pre_vocab[i])):\n",
    "    vocab.append(pre_vocab[i][j])\n",
    "\n",
    "vocab = list(set(vocab))\n",
    "vocab.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert GENIA documents into term-in-document matrix of token counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qXdBHbts5WmB"
   },
   "outputs": [],
   "source": [
    "# Helper function to ensure that CountVectorizer doesn't ignore any terms\n",
    "def analyzer_custom(doc):\n",
    "  return doc.split()\n",
    "\n",
    "# Generate term-in-document counts\n",
    "counter = CountVectorizer(lowercase=False, vocabulary=vocab, analyzer=analyzer_custom)\n",
    "collection = counter.transform(genia_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Term Dispersion Scores for Selected Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPmziX_0A5Kz"
   },
   "source": [
    "Calculate bag-of-words model word statistics and related quantities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nXvOPY8CqJlp"
   },
   "outputs": [],
   "source": [
    "# Calculate word statistics and related quantities\n",
    "m = len(counter.get_feature_names_out()) # vocab size\n",
    "d = collection.shape[0] # collection size\n",
    "N_i = wordstats.get_Ni(collection)\n",
    "N_j = wordstats.get_Nj(collection)\n",
    "N = wordstats.get_N(N_j)\n",
    "B_ij = wordstats.get_Bij(collection)\n",
    "B_i = wordstats.get_Bi(B_ij)\n",
    "B_j = wordstats.get_Bj(B_ij)\n",
    "DF = wordstats.get_DF(B_i, d)\n",
    "CF = wordstats.get_CF(N_i)\n",
    "nij_by_nj = wordstats.get_nij_by_nj(collection, N_j)\n",
    "thetas = np.array(range(1, max(N_i.A[0]) + 1))/N\n",
    "opt_thetas = wordstats.get_opt_thetas(N, m, d, N_i, N_j, B_i, thetas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate word dispersion scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate word dispersion scores according the various measures used in this study\n",
    "IDF = wordstats.get_IDF(DF)\n",
    "ICF = wordstats.get_ICF(CF)\n",
    "Chisq = wordstats.get_Chisq(collection)\n",
    "CG = wordstats.get_CG(N_i, B_i)\n",
    "ICB = wordstats.get_ICB(nij_by_nj, B_i)\n",
    "DoP = wordstats.get_DoP(collection, N_i, N_j, N)\n",
    "RICF = wordstats.get_RICF(opt_thetas, N, ICF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zX1-IBAVbCic"
   },
   "source": [
    "Arrange term dispersion scores into a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "VNAvUhBoeIqN"
   },
   "outputs": [],
   "source": [
    "# Initialize bursty scores data frame\n",
    "term_scores_df = pd.DataFrame(data=\n",
    "                         {'term': counter.get_feature_names_out(),\n",
    "                          'IDF': IDF.A[0],\n",
    "                          'ICF': ICF.A[0],\n",
    "                          'Chi-sq': Chisq,\n",
    "                          'CG': CG.A[0],\n",
    "                          'ICB': ICB.A[0],\n",
    "                          'DoP': DoP.A[0],\n",
    "                          'RICF': RICF.A[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print term dispersion scores to console\n",
    "display(term_scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to TSV\n",
    "term_scores_df.to_csv('term-dispersion-scores.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile GENIA Corpus Summary Statistics\n",
    "\n",
    "This is the result of Table 3 from the manuscript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect lexical units belonging to a given high-level semantic class\n",
    "def get_high_level_semantic_class_words(high_level_class_lst):\n",
    "  words = []\n",
    "  for k, v in lex_sem_dct.items():\n",
    "    if v in high_level_class_lst:\n",
    "      words.append(k)\n",
    "  return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hardcode the semantic classes according to their high-level designations.\n",
    "amino_acid_sems = ['G#amino_acid_monomer', 'G#peptide', 'G#protein_N/A',\n",
    "              'G#protein_complex', 'G#protein_domain_or_region',\n",
    "              'G#protein_family_or_group', 'G#protein_molecule',\n",
    "              'G#protein_substructure', 'G#protein_subunit',\n",
    "              'G#other_organic_compound', 'G#organic', 'G#inorganic', 'G#atom',\n",
    "              'G#carbohydrate', 'G#lipid']\n",
    "nucleotide_sems = ['G#nucleotide', 'G#polynucleotide', 'G#DNA_N/A',\n",
    "        'G#DNA_domain_or_region', 'G#DNA_family_or_group', 'G#DNA_molecule',\n",
    "        'G#DNA_substructure', 'G#RNA_N/A', 'G#RNA_domain_or_region',\n",
    "        'G#RNA_family_or_group', 'G#RNA_molecule', 'G#RNA_substructure']\n",
    "multi_cell_sems = ['G#virus', 'G#mono_cell', 'G#multi_cell', 'G#body_part', 'G#tissue']\n",
    "cell_sems = ['G#cell_type', 'G#cell_component', 'G#cell_line', 'G#other_artificial_source']\n",
    "other_sems = ['G#other_name']\n",
    "high_level_semantic_class_names = ['amino_acid', 'nucleotide', 'multi_cell', 'cell', 'other']\n",
    "high_level_semantic_class_lex_units = [genia_lexical_units, amino_acid_sems, nucleotide_sems, multi_cell_sems, cell_sems, other_sems]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of lexical units and their associated semantic classes\n",
    "sem = np.array(genia_lexical_units_and_sems['sem'])\n",
    "lex = np.array(genia_lexical_units_and_sems['lex'])\n",
    "lex_sem_dct = dict(zip(lex, sem))\n",
    "\n",
    "# Count number of semantic classes in each high-level class\n",
    "sub_class = [len(amino_acid_sems), len(nucleotide_sems), len(multi_cell_sems), len(cell_sems), len(other_sems)]\n",
    "\n",
    "# Count number of distinct lexical units in each high-level semantic class\n",
    "amino_acid = get_high_level_semantic_class_words(amino_acid_sems)\n",
    "nucleotide = get_high_level_semantic_class_words(nucleotide_sems)\n",
    "multi_cell = get_high_level_semantic_class_words(multi_cell_sems)\n",
    "cell = get_high_level_semantic_class_words(cell_sems)\n",
    "other = get_high_level_semantic_class_words(other_sems)\n",
    "\n",
    "# Count number of lexical units used as annotations for each high-level semantic class\n",
    "high_level_class_words = [genia_lexical_units, amino_acid, nucleotide, multi_cell, cell, other]\n",
    "high_level_class_words_counter = [0, 0, 0, 0, 0, 0]\n",
    "for i in range(len(high_level_class_words)):\n",
    "  for j in range(len(vocab)):\n",
    "    if vocab[j] in high_level_class_words[i]:\n",
    "      high_level_class_words_counter[i] += N_i.A[0][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of lexical units and their associated semantic classes\n",
    "sem = np.array(genia_lexical_units_and_sems['sem'])\n",
    "lex = np.array(genia_lexical_units_and_sems['lex'])\n",
    "lex_sem_dct = dict(zip(lex, sem))\n",
    "\n",
    "# Count number of semantic subclasses in each high-level class\n",
    "subclass_counts = [len(amino_acid_sems), len(nucleotide_sems), len(multi_cell_sems), len(cell_sems), len(other_sems)]\n",
    "\n",
    "# Gather distinct lexical units for each high-level semantic class\n",
    "amino_acid = get_high_level_semantic_class_words(amino_acid_sems)\n",
    "nucleotide = get_high_level_semantic_class_words(nucleotide_sems)\n",
    "multi_cell = get_high_level_semantic_class_words(multi_cell_sems)\n",
    "cell = get_high_level_semantic_class_words(cell_sems)\n",
    "other = get_high_level_semantic_class_words(other_sems)\n",
    "\n",
    "# Count number of lexical units used as annotations for each high-level semantic class\n",
    "lex_by_semamtic_class_counts = [0, 0, 0, 0, 0, 0]\n",
    "for i in range(len(high_level_semantic_class_names)):\n",
    "  for j in range(len(vocab)):\n",
    "    if vocab[j] in high_level_semantic_class_names[i]:\n",
    "      lex_by_semamtic_class_counts[i] += N_i.A[0][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data\n",
    "high_level_semantic_classes = ['all', 'amino_acid', 'nucleotide', 'multi_cell', 'cell', 'other']\n",
    "annotations_count_zip = zip(high_level_semantic_classes, high_level_class_words_counter)\n",
    "annotations_dict = dict(annotations_count_zip)\n",
    "lex_unit_counts = [len(amino_acid), len(nucleotide), len(multi_cell), len(cell), len(other)]\n",
    "subclass_counts = [len(amino_acid_sems), len(nucleotide_sems), len(multi_cell_sems), len(cell_sems), len(other_sems)]\n",
    "annotations = [\n",
    "    annotations_dict['amino_acid'],\n",
    "    annotations_dict['nucleotide'],\n",
    "    annotations_dict['multi_cell'],\n",
    "    annotations_dict['cell'],\n",
    "    annotations_dict['other']]\n",
    "\n",
    "# Create a data frame\n",
    "genia_summary_stats_df = pd.DataFrame({\n",
    "    'Semantic class': ['amino_acid', 'nucleotide', 'multi_cell', 'cell', 'other'],\n",
    "    'Sub-class': subclass_counts,\n",
    "    'Unique terms': lex_unit_counts,\n",
    "    \"Annotations\": annotations\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print GENIA summary statistics\n",
    "display(genia_summary_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to CSV\n",
    "genia_summary_stats_df.to_csv('table-3/table-3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminology Extraction Task Experiment\n",
    "\n",
    "Here we reproduce the result of Table 4 from the manuscript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k(dct, k):\n",
    "  keys = dct.keys()\n",
    "  values = []\n",
    "  for key in keys:\n",
    "    values.append(dct[key][:k])\n",
    "  keys_values_pair = zip(keys, values)\n",
    "  return dict(keys_values_pair)\n",
    "    \n",
    "def resort(term_scores_df):\n",
    "    sorted_terms = []\n",
    "    bursty_measure_names = term_scores_df.columns.values.tolist()[1:]\n",
    "\n",
    "    for measure in bursty_measure_names:\n",
    "        # Copy the data frame and add a random column\n",
    "        temp_df = term_scores_df.copy()\n",
    "        temp_df['random'] = np.random.rand(len(temp_df))\n",
    "        \n",
    "        # Sort by the measure and the random column\n",
    "        sorted_df = temp_df[['term', measure, 'random']].sort_values(by=[measure, 'random'], ascending=[False, True])\n",
    "        \n",
    "        # Append the sorted terms to the list\n",
    "        sorted_terms.append(np.array(sorted_df['term']))\n",
    "        \n",
    "        # Drop the random column from the temporary data frame\n",
    "        temp_df.drop(columns='random', inplace=True)\n",
    "    \n",
    "    sorted_terms = np.array(sorted_terms)\n",
    "    measure_term_pair = zip(bursty_measure_names, sorted_terms)\n",
    "    sorted_measures = dict(measure_term_pair)\n",
    "    return sorted_measures\n",
    "    \n",
    "def calculate_means(nested_list):\n",
    "    result = []\n",
    "    num_outer = len(nested_list)\n",
    "    num_inner = len(nested_list[0])\n",
    "\n",
    "    for i in range(num_inner):\n",
    "        means = {}\n",
    "        for column in nested_list[0][i].columns:\n",
    "            values = [nested_list[outer][i][column].values for outer in range(num_outer)]\n",
    "            mean_values = np.mean(values, axis=0)\n",
    "            means[column] = mean_values\n",
    "        result.append(pd.DataFrame(means, index=nested_list[0][i].index))\n",
    "    return result\n",
    "\n",
    "# Function to calculate the standard deviation of the corresponding data frames\n",
    "def calculate_sds(nested_list):\n",
    "    result = []\n",
    "    num_outer = len(nested_list)\n",
    "    num_inner = len(nested_list[0])\n",
    "\n",
    "    for i in range(num_inner):\n",
    "        std_devs = {}\n",
    "        for column in nested_list[0][i].columns:\n",
    "            values = [nested_list[outer][i][column].values for outer in range(num_outer)]\n",
    "            std_values = np.std(values, axis=0, ddof=1)\n",
    "            std_devs[column] = std_values\n",
    "        result.append(pd.DataFrame(std_devs, index=nested_list[0][i].index))\n",
    "    return result\n",
    "\n",
    "def create_p_k(v, sorted_measures):\n",
    "  measures = sorted_measures.keys()\n",
    "  counts = [[], [], [], [], [], [], [], [], [], []]\n",
    "  p_k_dct = dict(zip(measures, counts))  \n",
    "  for measure in p_k_dct.keys():\n",
    "      for value in at_values:\n",
    "              p_k_dct[measure].append(count_words(top_k(sorted_measures, value)[measure], v)/value)\n",
    "  result = pd.DataFrame(p_k_dct)\n",
    "  result.index = at_values\n",
    "  return result\n",
    "\n",
    "def create_r_k(v, sorted_measures):\n",
    "  measures = sorted_measures.keys()\n",
    "  counts = [[], [], [], [], [], [], [], [], [], []]\n",
    "  r_k_dct = dict(zip(measures, counts))  \n",
    "  for measure in r_k_dct.keys():\n",
    "      for value in at_values:\n",
    "              r_k_dct[measure].append(count_words(top_k(sorted_measures, value)[measure], v)/value)\n",
    "  result = pd.DataFrame(r_k_dct)\n",
    "  result.index = at_values\n",
    "  return result\n",
    "\n",
    "def create_f1_k(v, sorted_measures):\n",
    "  measures = sorted_measures.keys()\n",
    "  counts = [[], [], [], [], [], [], [], [], [], []]\n",
    "  f1_k_dct = dict(zip(measures, counts))  \n",
    "  for measure in f1_k_dct.keys():\n",
    "      for value in at_values:\n",
    "              f1_k_dct[measure].append(count_words(top_k(sorted_measures, value)[measure], v)/value)\n",
    "  result = pd.DataFrame(f1_k_dct)\n",
    "  result.index = at_values\n",
    "  return result\n",
    "\n",
    "def create_RBO(v, sorted_measures):\n",
    "  RICF = sorted_measures[\"RICF\"]\n",
    "  measures = sorted_measures.keys()\n",
    "  counts = [[], [], [], [], [], [], [], [], [], []]\n",
    "  rbo_dct = dict(zip(measures, counts))  \n",
    "  for measure in rbo_dct.keys():\n",
    "      for value in at_values:\n",
    "          S= top_k(sorted_measures, value)[measure]\n",
    "          T = RICF[0:value]\n",
    "          rbo_dct[measure].append(rbo.RankingSimilarity(S, T).rbo())\n",
    "  result = pd.DataFrame(rbo_dct)\n",
    "  result.index = at_values\n",
    "  return result\n",
    "\n",
    "\n",
    "\n",
    "def count_words(lst, imp_words):\n",
    "  counter = 0\n",
    "  for x in lst:\n",
    "    if x in imp_words:\n",
    "      counter += 1\n",
    "  return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a random seed to ensure results can be replicated\n",
    "np.random.seed(641369)\n",
    "\n",
    "# These are the P@k scores for the different categories of domain-specific words\n",
    "at_values = np.array([10, 50, 100, 500, 1000, 5000])\n",
    "categories = {'all': genia_lexical_units , 'amino_acid': amino_acid, 'nucleotide': nucleotide, 'multi_cell': multi_cell, 'cell': cell, 'other': other}\n",
    "all_pk_scores = []\n",
    "sds_dfs = []\n",
    "all_rbo_scores = []\n",
    "# R = 100\n",
    "R = 1 # For testing purposes; change back to 100 for final results\n",
    "for r in tqdm(range(R)):\n",
    " pk_scores = []\n",
    " sorted_measures = resort(term_scores_df)\n",
    " print(sorted_measures)\n",
    " for k, v in categories.items():\n",
    "     pk = create_p_k(v, sorted_measures)\n",
    "     rbo_scores= create_RBO(v, sorted_measures)\n",
    "     pk_scores.append(pk)\n",
    " all_pk_scores.append(pk_scores)\n",
    " all_rbo_scores.append(rbo_scores)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_measures\n",
    "_value = np.array([10, 50, 100, 500, 1000, 5000])\n",
    "RICF = sorted_measures[\"RICF\"]\n",
    "for i in sorted_measures.key():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the resulting data frames\n",
    "print(\"Mean P@k scores:\")\n",
    "with pd.option_context('display.precision', 4):\n",
    "    display(calculate_means(all_pk_scores)[0])\n",
    "    display(calculate_means(all_pk_scores)[1])\n",
    "    display(calculate_means(all_pk_scores)[2])\n",
    "    display(calculate_means(all_pk_scores)[3])\n",
    "    display(calculate_means(all_pk_scores)[4])\n",
    "    display(calculate_means(all_pk_scores)[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_rbo_scores)\n",
    "\n",
    "# with pd.option_context('display.precision', 4):\n",
    "#     display(calculate_means(all_rbo_scores)[0])\n",
    "#     display(calculate_means(all_rbo_scores)[1])\n",
    "#     display(calculate_means(all_rbo_scores)[2])\n",
    "#     display(calculate_means(all_rbo_scores)[3])\n",
    "#     display(calculate_means(all_rbo_scores)[4])\n",
    "#     display(calculate_means(all_rbo_scores)[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"P@k scores standard deviations:\")\n",
    "with pd.option_context('display.precision', 4):\n",
    "    display(calculate_sds(all_pk_scores)[0])\n",
    "    display(calculate_sds(all_pk_scores)[1])\n",
    "    display(calculate_sds(all_pk_scores)[2])\n",
    "    display(calculate_sds(all_pk_scores)[3])\n",
    "    display(calculate_sds(all_pk_scores)[4])\n",
    "    display(calculate_sds(all_pk_scores)[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean P@k scores and write to CSV\n",
    "pd.DataFrame(calculate_means(all_pk_scores)[0]).to_csv('table-4/table-4-all-means.csv', index=False)\n",
    "pd.DataFrame(calculate_means(all_pk_scores)[1]).to_csv('table-4/table-4-amino_acid-means.csv', index=False)\n",
    "pd.DataFrame(calculate_means(all_pk_scores)[2]).to_csv('table-4/table-4-nucleotide-means.csv', index=False)\n",
    "pd.DataFrame(calculate_means(all_pk_scores)[3]).to_csv('table-4/table-4-multicell-means.csv', index=False)\n",
    "pd.DataFrame(calculate_means(all_pk_scores)[4]).to_csv('table-4/table-4-cell-means.csv', index=False)\n",
    "pd.DataFrame(calculate_means(all_pk_scores)[5]).to_csv('table-4/table-4-other-means.csv', index=False)\n",
    "\n",
    "# Calculate standard deviations for P@k scores and write to CSV\n",
    "pd.DataFrame(calculate_sds(all_pk_scores)[0]).to_csv('table-4/table-4-all-sds.csv', index=False)\n",
    "pd.DataFrame(calculate_sds(all_pk_scores)[1]).to_csv('table-4/table-4-amino_acid-sds.csv', index=False)\n",
    "pd.DataFrame(calculate_sds(all_pk_scores)[2]).to_csv('table-4/table-4-nucleotide-sds.csv', index=False)\n",
    "pd.DataFrame(calculate_sds(all_pk_scores)[3]).to_csv('table-4/table-4-multicell-sds.csv', index=False)\n",
    "pd.DataFrame(calculate_sds(all_pk_scores)[4]).to_csv('table-4/table-4-cell-sds.csv', index=False)\n",
    "pd.DataFrame(calculate_sds(all_pk_scores)[5]).to_csv('table-4/table-4-other-sds.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 10 Ranked Terms Example\n",
    "\n",
    "Here we reproduce the result of Table 5 from the manuscript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a random seed to ensure results can be replicated\n",
    "np.random.seed(641369)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_terms_df = resort(term_scores_df)\n",
    "top_10_ranked_terms_df = pd.DataFrame(top_k(ranked_terms_df, 10))\n",
    "display(top_10_ranked_terms_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to CSV\n",
    "top_10_ranked_terms_df.to_csv('table-5/table-5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopwords Exploratory Analysis\n",
    "\n",
    "Here we reproduce the result of Table 6 from the manuscript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Ensure you have the stopwords downloaded\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def getrank(sorted_measures):\n",
    "    unique_terms = set()\n",
    "    for terms in sorted_measures.values():\n",
    "        unique_terms.update(terms)\n",
    "    unique_terms = sorted(unique_terms)\n",
    "    \n",
    "    # Create a data frame to hold the rankings\n",
    "    ranking_df = pd.DataFrame(index=unique_terms, columns=sorted_measures.keys())\n",
    "    \n",
    "    # Fill the data frame with rankings\n",
    "    for measure, terms in sorted_measures.items():\n",
    "        for rank, term in enumerate(terms):\n",
    "            ranking_df.at[term, measure] = rank + 1  # Rank starts from 1\n",
    "    \n",
    "    # Replace NaN with a large number to indicate unranked terms\n",
    "    ranking_df = ranking_df.fillna(len(unique_terms) + 1)\n",
    "    #csv_file_path = 'ranking_table.csv'\n",
    "    #ranking_df.to_csv(csv_file_path)\n",
    "    return ranking_df\n",
    "\n",
    "# Function to filter stopwords from the ranking data frame\n",
    "def filter_stopwords(ranking_df):\n",
    "    stopwords_list = set(stopwords.words('english'))\n",
    "    \n",
    "    # Filter the data frame to include only stopwords\n",
    "    stopwords_rank = ranking_df[ranking_df.index.isin(stopwords_list)]\n",
    "    \n",
    "    # Save the stopwords ranking data frame to a CSV file\n",
    "    #csv_file_path = 'stopwords_ranking_table.csv'\n",
    "    #stopwords_rank.to_csv(csv_file_path)\n",
    "    \n",
    "    return stopwords_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a random seed to ensure results can be replicated\n",
    "np.random.seed(641369)\n",
    "\n",
    "# Generate term dispersion ranks for R different versions of the data\n",
    "R = 100\n",
    "all_quantiles_df = []\n",
    "for r in tqdm(range(R)):\n",
    "    sorted_measures = resort(term_scores_df)\n",
    "    rank = getrank(sorted_measures)\n",
    "    stopwords_ranks_df = filter_stopwords(rank)\n",
    "    bursty_measure_names = stopwords_ranks_df.head(0)\n",
    "    quantiles = []\n",
    "    for bursty_measure_name in bursty_measure_names:\n",
    "        quantiles.append(stopwords_ranks_df[bursty_measure_name].quantile([0, 0.25, 0.5, 0.75, 1]))\n",
    "    quantiles_df = pd.DataFrame(quantiles)\n",
    "    all_quantiles_df.append(quantiles_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the column and index names from the first quantiles data frame\n",
    "columns = all_quantiles_df[0].columns\n",
    "index = all_quantiles_df[0].index\n",
    "\n",
    "# Initialize empty data frames to store the mean and standard deviation values\n",
    "mean_df = pd.DataFrame(index=index, columns=columns)\n",
    "std_df = pd.DataFrame(index=index, columns=columns)\n",
    "\n",
    "# Compute the mean and standard deviation of corresponding elements across all matrices\n",
    "for col in columns:\n",
    "    for idx in index:\n",
    "        values = [matrix.at[idx, col] for matrix in all_quantiles_df]\n",
    "        mean_df.at[idx, col] = np.mean(values)\n",
    "        std_df.at[idx, col] = np.std(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the resulting data frames\n",
    "print(\"Mean values:\")\n",
    "with pd.option_context('display.precision', 4):\n",
    "    display(mean_df)\n",
    "print(\"\\nStandard deviations:\")\n",
    "with pd.option_context('display.precision', 4):\n",
    "    display(std_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to CSV\n",
    "mean_df.to_csv('table-6/table-6-means.csv')\n",
    "std_df.to_csv('table-6/table-6-sds.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "91NU-MJcn4rq",
    "FPsrW3ClAKBo"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
